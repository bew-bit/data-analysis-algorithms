{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе задания выполнить модификации выражений для рассчёта функции потерь линейной регресси и её градиента, связанные с добавлением регулярязационной l2 поправки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возьмем 2 признака и 1000 объектов\n",
    "n_features = 2\n",
    "n_objects = 1000\n",
    "\n",
    "# сгенерируем вектор истинных весов\n",
    "w_true = np.random.normal(size=(1, n_features ))\n",
    "\n",
    "# сгенерируем матрицу X, вычислим Y с добавлением случайного шума\n",
    "X = np.random.uniform(-7, 7, (n_objects, n_features))\n",
    "Y = X.dot(w_true.T) + np.random.normal(0, 0.5, size=(n_objects, 1))\n",
    "\n",
    "# возьмем нулевые начальные веса\n",
    "w = np.zeros((1, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_regression:\n",
    "    def __init__(self, eta = 0.9, max_iter = 1e4, min_weight_dist = 1e-8):\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        self.min_weight_dist = min_weight_dist\n",
    "    def _mserror(self, X, y_real):\n",
    "        #рассчёт среднеквадратичной ошибки\n",
    "        y = X.dot(self.w.T)+self.w0\n",
    "        return np.sum((y - y_real)**2) / y_real.shape[0]\n",
    "    def _mserror_grad(self, X, y_real):\n",
    "        #рассчёт градиента ошибки.\n",
    "        #2*delta.T.dot(X)/y_real.shape[0] - градиент по коэффициентам при факторах\n",
    "        #np.sum(2*delta)/y_real.shape[0] - производная(градиент) при нулевом коэффициенте\n",
    "        delta=(X.dot(self.w.T)+self.w0-y_real)\n",
    "        return 2*delta.T.dot(X)/y_real.shape[0], np.sum(2*delta)/y_real.shape[0]    \n",
    "    def _optimize(self, X, Y):\n",
    "        #оптимизация коэффициентов\n",
    "        iter_num = 0\n",
    "        weight_dist = np.inf\n",
    "        self.w = np.zeros((1, X.shape[1]))\n",
    "        self.w0=0\n",
    "        while weight_dist > self.min_weight_dist and iter_num < self.max_iter:\n",
    "            gr_w, gr_w0=self._mserror_grad(X, Y)\n",
    "            if iter_num==0:\n",
    "                #Чтобы eta адаптировалась к порядку градиента, делим на l2 норму градиента в нуле\n",
    "                eta=self.eta/np.sqrt(np.linalg.norm(gr_w)**2+(gr_w0)**2)\n",
    "            new_w = self.w - eta * gr_w\n",
    "            new_w0= self.w0 - eta * gr_w0\n",
    "            weight_dist = np.sqrt(np.linalg.norm(new_w - self.w)**2+(new_w0 - self.w0)**2)\n",
    "            iter_num += 1\n",
    "            self.w = new_w\n",
    "            self.w0 = new_w0\n",
    "    def fit(self, X, Y):\n",
    "        if Y.ndim==1:\n",
    "            Y=Y[:, np.newaxis]\n",
    "        self._optimize(X, Y)\n",
    "    def predict(self, X):\n",
    "        return (X.dot(self.w.T)+self.w0).flatten()\n",
    "    def test(self, X, Y):\n",
    "        if Y.ndim==1:\n",
    "            Y=Y[:, np.newaxis]\n",
    "        return self._mserror(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2604509190760605"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift=np.random.uniform(0, 100)\n",
    "Y_shift=Y+shift\n",
    "lr=linear_regression()\n",
    "lr.fit(X, Y_shift)\n",
    "lr.test(X, Y_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49.93681885158912, 49.935484155830736)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift, lr.w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.2805911 , 1.30202252]]), array([[1.28205034, 1.30261407]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.w, w_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2604509190760605"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((lr.predict(X)-Y_shift.flatten())**2)/Y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Регуляризация уменьшает сложность модели для предотвращения переобучени.<br/>\n",
    "L1-регуляризация \"штрафует\" весовые значения добавлением суммы их абсолютных значений к ошибке.<br/>\n",
    "$$\n",
    "L(\\beta) = \\frac1n \\cdot \\sum_{i=1}^n (y_i - (\\beta_0 + \\beta_1 \\cdot x_1 + ... + \\beta_n \\cdot x_n))^2 + \\lambda \\cdot \\sum |\\beta_n|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class linear_regression:\n",
    "    def __init__(self, eta = 0.9, _lambda=0.001, max_iter = 1e4, min_weight_dist = 1e-8):\n",
    "        self.eta = eta\n",
    "        self.max_iter = max_iter\n",
    "        self.min_weight_dist = min_weight_dist\n",
    "        self._lambda = _lambda\n",
    "    def _mserror(self, X, y_real):\n",
    "        #рассчёт среднеквадратичной ошибки\n",
    "        y = X.dot(self.w.T)+self.w0\n",
    "        reg = np.sum(self.w)**2+self.w0**2\n",
    "        return np.sum((y - y_real)**2) / y_real.shape[0]+self._lambda*reg\n",
    "    def _mserror_grad(self, X, y_real):\n",
    "        #рассчёт градиента ошибки.\n",
    "        #2*delta.T.dot(X)/y_real.shape[0] - градиент по коэффициентам при факторах\n",
    "        #np.sum(2*delta)/y_real.shape[0] - производная(градиент) при нулевом коэффициенте\n",
    "        delta=(X.dot(self.w.T)+self.w0-y_real)\n",
    "        reg_grad_w = self.w\n",
    "        reg_grad_w0 = 2*self.w0\n",
    "        return (2*delta.T.dot(X)/y_real.shape[0]+self._lambda*reg_grad_w,\n",
    "                np.sum(2*delta)/y_real.shape[0]+self._lambda*reg_grad_w0)\n",
    "    def _optimize(self, X, Y):\n",
    "        #оптимизация коэффициентов\n",
    "        iter_num = 0\n",
    "        weight_dist = np.inf\n",
    "        self.w = np.zeros((1, X.shape[1]))\n",
    "        self.w0=0\n",
    "        while weight_dist > self.min_weight_dist and iter_num < self.max_iter:\n",
    "            gr_w, gr_w0=self._mserror_grad(X, Y)\n",
    "            if iter_num==0:\n",
    "                #Чтобы eta адаптировалась к порядку градиента, делим на l2 норму градиента в нуле\n",
    "                eta=self.eta/np.sqrt(np.linalg.norm(gr_w)**2+(gr_w0)**2)\n",
    "            new_w = self.w - eta * gr_w\n",
    "            new_w0= self.w0 - eta * gr_w0\n",
    "            weight_dist = np.sqrt(np.linalg.norm(new_w - self.w)**2+(new_w0 - self.w0)**2)\n",
    "            iter_num += 1\n",
    "            self.w = new_w\n",
    "            self.w0 = new_w0\n",
    "    def fit(self, X, Y):\n",
    "        if Y.ndim==1:\n",
    "            Y=Y[:, np.newaxis]\n",
    "        self._optimize(X, Y)\n",
    "    def predict(self, X):\n",
    "        return (X.dot(self.w.T)+self.w0).flatten()\n",
    "    def test(self, X, Y):\n",
    "        if Y.ndim==1:\n",
    "            Y=Y[:, np.newaxis]\n",
    "        return self._mserror(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6096692611079018"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift=np.random.uniform(0, 100)\n",
    "Y_shift=Y+shift\n",
    "lr=linear_regression()\n",
    "lr.fit(X, Y_shift)\n",
    "lr.test(X, Y_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57.84500777079988, 57.7858692171561)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift, lr.w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.28074008, 1.30219239]]), array([[1.28205034, 1.30261407]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.w, w_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2637910398035859"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((lr.predict(X)-Y_shift.flatten())**2)/Y.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
